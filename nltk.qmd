---
title: "Natural Lenguaje ToolKit"
---

# Ejemplo de Categorias

## Importación de Librerias

```{python}
import pandas as pd
import requests
 
# Natural Language Toolkit
import nltk
# downloading some additional packages and corpora
nltk.download('punkt_tab') # necessary for tokenization
nltk.download('wordnet') # necessary for lemmatization
nltk.download('stopwords') # necessary for removal of stop words
nltk.download('averaged_perceptron_tagger_eng') # necessary for POS tagging
nltk.download('maxent_ne_chunker' ) # necessary for entity extraction
nltk.download('omw-1.4') # necessary for lemmatization
nltk.download('words')
```

## Dataframe NLTK

```{python}
url = "https://raw.githubusercontent.com/erickedu85/dataset/master/story.txt"
r = requests.get(url)
r.encoding = "utf-8"

story = r.text
story
```

## Tokenización
```{python}
from nltk import word_tokenize, pos_tag

words = word_tokenize(story)
words[:20]
```

```{python}

from nltk.stem import PorterStemmer, WordNetLemmatizer
from nltk.corpus import wordnet

palabra = "change"
# Instanciar los objetos
stemmer = PorterStemmer()
lemmatizer = WordNetLemmatizer()

# Stemming
print("STEMMING:", stemmer.stem(palabra))

# Lemmatization
print("LEMMATIZATION:", lemmatizer.lemmatize(palabra, pos=wordnet.VERB))

```


```{python}
pos = pos_tag(words)
pos[:20]
```



```{python}
from nltk.corpus import stopwords as stop

for item in stop.words("spanish"):
    print(item)
```


```{python}

for item in stop.words("english"):
    print(item)
```

# Stop Words in Story

```{python}
from nltk.corpus import stopwords
tokens = nltk.word_tokenize(story.lower())
tokens[:50]

lettertokens = [word for word in tokens if word.isalpha()]
stop_words = set(stopwords.words('english'))
# Eliminar las stopwords
without_stopwords = [word for word in lettertokens if word not in stop_words]
without_stopwords[:50]
```



#Corpus